#!/usr/bin/env python3
"""
macOS ç£ç›˜ç©ºé—´åˆ†æå·¥å…·
é€’å½’æ‰«ææ–‡ä»¶ç³»ç»Ÿï¼Œåˆ†æç©ºé—´å ç”¨æƒ…å†µ
"""

import argparse
import sys
import os
import webbrowser
import tempfile
import subprocess
from datetime import datetime

# ç‰ˆæœ¬å·
VERSION = "1.1.0"

# å°è¯•å¯¼å…¥ rich åº“ç”¨äºæ›´å¥½çš„è¿›åº¦æ˜¾ç¤º
try:
    from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn
    from rich.console import Console
    from rich.live import Live
    from rich.table import Table
    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False

from disk_analyzer.scanner import DiskScanner, parse_size, DuplicateFinder, format_size
from disk_analyzer.analyzer import SpaceAnalyzer
from disk_analyzer.reporter import TerminalReporter, JSONReporter, HTMLReporter


def create_parser():
    """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        prog='disk-analyzer',
        description='macOS ç£ç›˜ç©ºé—´åˆ†æå·¥å…· - å¸®åŠ©ä½ æ‰¾å‡ºå ç”¨ç©ºé—´çš„æ–‡ä»¶å’Œç›®å½•',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ç¤ºä¾‹:
  python main.py ~                      # åˆ†æç”¨æˆ·ä¸»ç›®å½•
  python main.py / --depth 3            # åˆ†ææ ¹ç›®å½•ï¼Œé™åˆ¶æ·±åº¦ä¸º3
  python main.py . --top 30             # æ˜¾ç¤ºå‰30ä¸ªæœ€å¤§é¡¹
  python main.py ~/Downloads --min-size 10MB   # åªç»Ÿè®¡å¤§äº10MBçš„æ–‡ä»¶
  python main.py / --exclude node_modules,.git # æ’é™¤ç‰¹å®šç›®å½•
  python main.py . --output report.html        # ç”Ÿæˆ HTML æŠ¥å‘Š
  python main.py . --json report.json          # ç”Ÿæˆ JSON æŠ¥å‘Š
        '''
    )
    
    parser.add_argument(
        'path',
        nargs='?',
        default='.',
        help='è¦åˆ†æçš„ç›®å½•è·¯å¾„ (é»˜è®¤: å½“å‰ç›®å½•)'
    )
    
    parser.add_argument(
        '--depth', '-d',
        type=int,
        default=None,
        help='æœ€å¤§æ‰«ææ·±åº¦ (é»˜è®¤: æ— é™åˆ¶)'
    )
    
    parser.add_argument(
        '--top', '-n',
        type=int,
        default=15,
        help='æ˜¾ç¤ºå‰ N ä¸ªæœ€å¤§é¡¹ (é»˜è®¤: 15)'
    )
    
    parser.add_argument(
        '--min-size', '-m',
        type=str,
        default='0',
        help='æœ€å°æ–‡ä»¶å¤§å°ï¼Œæ”¯æŒå•ä½å¦‚ 1KB, 10MB, 1GB (é»˜è®¤: 0)'
    )
    
    parser.add_argument(
        '--exclude', '-e',
        type=str,
        default='',
        help='è¦æ’é™¤çš„ç›®å½•ï¼Œç”¨é€—å·åˆ†éš” (å¦‚: node_modules,.git,__pycache__)'
    )
    
    parser.add_argument(
        '--output', '-o',
        type=str,
        default=None,
        help='è¾“å‡º HTML æŠ¥å‘Šåˆ°æŒ‡å®šæ–‡ä»¶ (é»˜è®¤è‡ªåŠ¨ç”Ÿæˆä¸´æ—¶æ–‡ä»¶)'
    )
    
    parser.add_argument(
        '--no-browser',
        action='store_true',
        help='ä¸è‡ªåŠ¨åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€æŠ¥å‘Š'
    )
    
    parser.add_argument(
        '--no-html',
        action='store_true',
        help='ä¸ç”Ÿæˆ HTML æŠ¥å‘Šï¼ˆä»…ç»ˆç«¯è¾“å‡ºï¼‰'
    )
    
    parser.add_argument(
        '--json', '-j',
        type=str,
        default=None,
        help='è¾“å‡º JSON æŠ¥å‘Šåˆ°æŒ‡å®šæ–‡ä»¶'
    )
    
    parser.add_argument(
        '--tree-depth',
        type=int,
        default=2,
        help='ç›®å½•æ ‘æ˜¾ç¤ºæ·±åº¦ (é»˜è®¤: 2)'
    )
    
    parser.add_argument(
        '--no-color',
        action='store_true',
        help='ç¦ç”¨å½©è‰²è¾“å‡º'
    )
    
    parser.add_argument(
        '--follow-symlinks',
        action='store_true',
        help='è·Ÿéšç¬¦å·é“¾æ¥ (é»˜è®¤: ä¸è·Ÿéš)'
    )
    
    parser.add_argument(
        '--show-errors',
        action='store_true',
        help='æ˜¾ç¤ºæ‰€æœ‰æ‰«æé”™è¯¯'
    )
    
    parser.add_argument(
        '--update',
        action='store_true',
        help='æ›´æ–°å·¥å…·åˆ°æœ€æ–°ç‰ˆæœ¬'
    )
    
    parser.add_argument(
        '--version', '-v',
        action='store_true',
        help='æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯'
    )
    
    parser.add_argument(
        '--find-duplicates',
        action='store_true',
        help='æ£€æµ‹é‡å¤æ–‡ä»¶ï¼ˆå¯èƒ½è€—æ—¶è¾ƒé•¿ï¼‰'
    )
    
    parser.add_argument(
        '--dup-min-size',
        type=str,
        default='10KB',
        help='é‡å¤æ£€æµ‹æœ€å°æ–‡ä»¶å¤§å° (é»˜è®¤: 10KB)'
    )
    
    return parser


def do_update():
    """æ›´æ–°å·¥å…·åˆ°æœ€æ–°ç‰ˆæœ¬"""
    # è·å–å·¥å…·å®‰è£…ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    print(f"ğŸ”„ æ­£åœ¨æ›´æ–° disk-analyzer...")
    print(f"   å®‰è£…ç›®å½•: {script_dir}")
    print()
    
    try:
        # æ£€æŸ¥æ˜¯å¦æ˜¯ git ä»“åº“
        if not os.path.exists(os.path.join(script_dir, '.git')):
            print("âŒ é”™è¯¯: å½“å‰ç›®å½•ä¸æ˜¯ git ä»“åº“ï¼Œæ— æ³•æ›´æ–°")
            print("   è¯·ä½¿ç”¨ git clone é‡æ–°å®‰è£…å·¥å…·")
            sys.exit(1)
        
        # è·å–å½“å‰ç‰ˆæœ¬
        current_commit = subprocess.run(
            ['git', 'rev-parse', '--short', 'HEAD'],
            cwd=script_dir,
            capture_output=True,
            text=True
        ).stdout.strip()
        print(f"   å½“å‰ç‰ˆæœ¬: {VERSION} ({current_commit})")
        
        # æ£€æŸ¥è¿œç¨‹æ›´æ–°
        print("   æ£€æŸ¥è¿œç¨‹æ›´æ–°...")
        subprocess.run(['git', 'fetch'], cwd=script_dir, capture_output=True)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ›´æ–°
        status = subprocess.run(
            ['git', 'status', '-uno'],
            cwd=script_dir,
            capture_output=True,
            text=True
        ).stdout
        
        if 'Your branch is up to date' in status:
            print("\nâœ… å·²ç»æ˜¯æœ€æ–°ç‰ˆæœ¬ï¼")
            return
        
        # æ‹‰å–æœ€æ–°ä»£ç 
        print("   æ‹‰å–æœ€æ–°ä»£ç ...")
        result = subprocess.run(
            ['git', 'pull', '--rebase'],
            cwd=script_dir,
            capture_output=True,
            text=True
        )
        
        if result.returncode != 0:
            print(f"âŒ æ›´æ–°å¤±è´¥: {result.stderr}")
            sys.exit(1)
        
        # è·å–æ–°ç‰ˆæœ¬
        new_commit = subprocess.run(
            ['git', 'rev-parse', '--short', 'HEAD'],
            cwd=script_dir,
            capture_output=True,
            text=True
        ).stdout.strip()
        
        print(f"\nâœ… æ›´æ–°æˆåŠŸï¼")
        print(f"   æ–°ç‰ˆæœ¬: {new_commit}")
        
        # æ˜¾ç¤ºæ›´æ–°æ—¥å¿—
        print("\nğŸ“ æ›´æ–°å†…å®¹:")
        log = subprocess.run(
            ['git', 'log', f'{current_commit}..{new_commit}', '--oneline'],
            cwd=script_dir,
            capture_output=True,
            text=True
        ).stdout.strip()
        
        if log:
            for line in log.split('\n'):
                print(f"   â€¢ {line}")
        
    except FileNotFoundError:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° git å‘½ä»¤ï¼Œè¯·å…ˆå®‰è£… git")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ æ›´æ–°å¤±è´¥: {e}")
        sys.exit(1)


def show_version():
    """æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    print(f"disk-analyzer v{VERSION}")
    print(f"macOS ç£ç›˜ç©ºé—´åˆ†æå·¥å…·")
    
    # è·å– git ä¿¡æ¯
    try:
        if os.path.exists(os.path.join(script_dir, '.git')):
            commit = subprocess.run(
                ['git', 'rev-parse', '--short', 'HEAD'],
                cwd=script_dir,
                capture_output=True,
                text=True
            ).stdout.strip()
            print(f"Git commit: {commit}")
    except:
        pass
    
    print(f"\nå®‰è£…è·¯å¾„: {script_dir}")
    print("GitHub: https://github.com/openingax/disk-analyzer")


def print_progress_simple(current_path: str, files: int, dirs: int):
    """ç®€å•çš„è¿›åº¦æ˜¾ç¤º"""
    # æˆªæ–­è¿‡é•¿çš„è·¯å¾„
    if len(current_path) > 50:
        display_path = '...' + current_path[-47:]
    else:
        display_path = current_path.ljust(50)
    
    sys.stdout.write(f'\ræ­£åœ¨æ‰«æ: {files:,} æ–‡ä»¶, {dirs:,} ç›®å½• | {display_path}')
    sys.stdout.flush()


def main():
    """ä¸»å‡½æ•°"""
    parser = create_parser()
    args = parser.parse_args()
    
    # å¤„ç† --version å‚æ•°
    if args.version:
        show_version()
        return
    
    # å¤„ç† --update å‚æ•°
    if args.update:
        do_update()
        return
    
    # è§£æè·¯å¾„
    target_path = os.path.abspath(os.path.expanduser(args.path))
    
    if not os.path.exists(target_path):
        print(f"é”™è¯¯: è·¯å¾„ä¸å­˜åœ¨: {target_path}", file=sys.stderr)
        sys.exit(1)
    
    if not os.path.isdir(target_path):
        print(f"é”™è¯¯: ä¸æ˜¯ç›®å½•: {target_path}", file=sys.stderr)
        sys.exit(1)
    
    # è§£æå‚æ•°
    try:
        min_size = parse_size(args.min_size)
    except ValueError:
        print(f"é”™è¯¯: æ— æ•ˆçš„å¤§å°æ ¼å¼: {args.min_size}", file=sys.stderr)
        sys.exit(1)
    
    exclude_patterns = set()
    if args.exclude:
        exclude_patterns = set(p.strip() for p in args.exclude.split(','))
    
    # æ‰“å°å¼€å§‹ä¿¡æ¯
    print()
    print("ğŸ” macOS ç£ç›˜ç©ºé—´åˆ†æå·¥å…·")
    print("=" * 50)
    print(f"   æ‰«æè·¯å¾„: {target_path}")
    if args.depth:
        print(f"   æœ€å¤§æ·±åº¦: {args.depth}")
    if min_size > 0:
        print(f"   æœ€å°æ–‡ä»¶: {args.min_size}")
    if exclude_patterns:
        print(f"   æ’é™¤ç›®å½•: {', '.join(exclude_patterns)}")
    print("=" * 50)
    print()
    
    # åˆ›å»ºæ‰«æå™¨
    scanner = DiskScanner(
        exclude_patterns=exclude_patterns,
        min_size=min_size,
        max_depth=args.depth,
        follow_symlinks=args.follow_symlinks,
        progress_callback=print_progress_simple
    )
    
    # å¼€å§‹æ‰«æ
    start_time = datetime.now()
    print("å¼€å§‹æ‰«æ...")
    
    try:
        result = scanner.scan(target_path)
    except KeyboardInterrupt:
        print("\n\næ‰«æè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except PermissionError:
        print(f"\né”™è¯¯: æ— æ³•è®¿é—®ç›®å½• {target_path}ï¼Œè¯·æ£€æŸ¥æƒé™", file=sys.stderr)
        sys.exit(1)
    
    # æ¸…é™¤è¿›åº¦è¡Œ
    sys.stdout.write('\r' + ' ' * 80 + '\r')
    sys.stdout.flush()
    
    elapsed = datetime.now() - start_time
    print(f"âœ… æ‰«æå®Œæˆ! è€—æ—¶: {elapsed.total_seconds():.1f} ç§’")
    print()
    
    # ç”Ÿæˆç»ˆç«¯æŠ¥å‘Š
    use_colors = not args.no_color and sys.stdout.isatty()
    reporter = TerminalReporter(result, use_colors=use_colors)
    reporter.print_full_report(tree_depth=args.tree_depth)
    
    # ç”Ÿæˆ HTML æŠ¥å‘Š
    if not args.no_html:
        html_reporter = HTMLReporter(result)
        
        if args.output:
            html_path = args.output
        else:
            # ç”Ÿæˆä¸´æ—¶æ–‡ä»¶
            temp_dir = tempfile.gettempdir()
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            html_path = os.path.join(temp_dir, f'disk_report_{timestamp}.html')
        
        html_reporter.generate_report(html_path)
        
        # è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨
        if not args.no_browser:
            print(f"ğŸŒ æ­£åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€æŠ¥å‘Š...")
            webbrowser.open(f'file://{os.path.abspath(html_path)}')
    
    # ç”Ÿæˆ JSON æŠ¥å‘Š
    if args.json:
        json_reporter = JSONReporter(result)
        json_reporter.generate_report(args.json)
    
    # æ˜¾ç¤ºé”™è¯¯
    if args.show_errors and result.errors:
        print("\næ‰€æœ‰æ‰«æé”™è¯¯:")
        for error in result.errors:
            print(f"  â€¢ {error}")
    
    # é‡å¤æ–‡ä»¶æ£€æµ‹
    if args.find_duplicates:
        print()
        print("=" * 60)
        print("ğŸ” æ­£åœ¨æ£€æµ‹é‡å¤æ–‡ä»¶...")
        print("=" * 60)
        
        try:
            dup_min_size = parse_size(args.dup_min_size)
        except ValueError:
            dup_min_size = 10 * 1024  # é»˜è®¤ 10KB
        
        def dup_progress(current, total, stage):
            stage_names = {
                'size_group': 'æŒ‰å¤§å°åˆ†ç»„',
                'partial_hash': 'è®¡ç®—éƒ¨åˆ†å“ˆå¸Œ',
                'full_hash': 'è®¡ç®—å®Œæ•´å“ˆå¸Œ'
            }
            stage_name = stage_names.get(stage, stage)
            if total > 0:
                sys.stdout.write(f'\r   {stage_name}: {current}/{total} ({current*100//total}%)')
                sys.stdout.flush()
        
        finder = DuplicateFinder(
            min_size=dup_min_size,
            progress_callback=dup_progress
        )
        
        dup_start = datetime.now()
        duplicates = finder.find_duplicates(result.all_files)
        dup_elapsed = datetime.now() - dup_start
        
        # æ¸…é™¤è¿›åº¦è¡Œ
        sys.stdout.write('\r' + ' ' * 60 + '\r')
        sys.stdout.flush()
        
        if duplicates:
            summary = finder.get_summary(duplicates)
            
            print(f"\nâœ… æ£€æµ‹å®Œæˆ! è€—æ—¶: {dup_elapsed.total_seconds():.1f} ç§’\n")
            print(f"   å‘ç° {summary['total_groups']} ç»„é‡å¤æ–‡ä»¶")
            print(f"   æ¶‰åŠ {summary['total_files']} ä¸ªæ–‡ä»¶")
            print(f"   ğŸ’¾ å¯é‡Šæ”¾ç©ºé—´: {summary['formatted_wasted']}")
            print()
            
            # æ˜¾ç¤ºå‰ 10 ç»„é‡å¤æ–‡ä»¶
            print("ğŸ“„ æœ€å¤§çš„é‡å¤æ–‡ä»¶ç»„:")
            print("-" * 60)
            
            for i, group in enumerate(duplicates[:10], 1):
                print(f"\n   {i}. [{group.count} ä»½] {group.formatted_size} (å¯é‡Šæ”¾ {group.formatted_wasted})")
                for j, f in enumerate(group.files[:3]):
                    prefix = "     â””â”€â”€ " if j == min(2, len(group.files) - 1) else "     â”œâ”€â”€ "
                    path_display = f.path
                    if len(path_display) > 50:
                        path_display = '...' + path_display[-47:]
                    print(f"{prefix}{path_display}")
                if len(group.files) > 3:
                    print(f"     â””â”€â”€ ... è¿˜æœ‰ {len(group.files) - 3} ä¸ªæ–‡ä»¶")
            
            if len(duplicates) > 10:
                print(f"\n   ... è¿˜æœ‰ {len(duplicates) - 10} ç»„é‡å¤æ–‡ä»¶")
            print()
        else:
            print(f"\nâœ… æ£€æµ‹å®Œæˆ! æœªå‘ç°é‡å¤æ–‡ä»¶ (æœ€å°æ£€æµ‹å¤§å°: {format_size(dup_min_size)})\n")


if __name__ == '__main__':
    main()
